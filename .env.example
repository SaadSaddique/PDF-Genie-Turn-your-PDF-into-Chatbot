# Providers (Gemini-only for now, but keep shape for future)
LLM_PROVIDER=gemini
EMBED_PROVIDER=gemini

# Gemini models
GEMINI_MODEL=models/gemini-1.5-flash
GEMINI_EMBED_MODEL=text-embedding-004

# Keys
GEMINI_API_KEY=

# Vector store
VECTOR_STORE=chroma
INDEX_DIR=./data/index

# Chunking
CHUNKER=sentence         # sentence | token
CHUNK_SIZE=800           # chars for sentence; tokens for token
CHUNK_OVERLAP=120

# Retrieval
TOP_K=5
USE_MMR=true             # reserved (MMR hook in query step)

# LLM gen
MAX_TOKENS=800
TEMPERATURE=0.2
